---
title: "Wrangling Data"
author: "Dominguez Center for Data Science Workshop"
date: "3-21-2025"
format: pdf
execute:
  warning: false
  message: false
editor_options: 
  chunk_output_type: console
---

# Questions Round-Up

## How can I provide comments with my code?

* Outside of a code chunk, # = Create Section header, ## = Create sub-section header, ... 

* Instead of a code chunk, # = Don't run whatever is after this pound symbol

```{r}
# Load the needed packages
library(tidyverse)

# 2 + 2
```

## Any other questions?


# Plan for today

-   Recap data wrangling functions we covered last time.
-   Learn about chaining data wrangling operations together with the pipe (`%>%` or `|>`).
-   Go through the "more_wrangling_key.qmd" Quarto document.
-   Remember that you can either fill in the "more_wrangling.qmd" file or follow along with the "more_wrangling_key.qmd" file.

# Load Packages

The packages we need for our explorations today (`readr` for reading in data, `ggplot2` for graphing data, and `dplyr` for wrangling/summarizing the data) are part of a popular suite of packages called the `tidyverse`.

```{r}
library(tidyverse)
```

# Data Background

We will return to the same dataset we saw last time. Here's the background and description of the variables.

In 2013, the government decided to make data about colleges more accessible so that students and parents could more easily compare schools. These data are called the ["College Scorecard" data](https://collegescorecard.ed.gov/) and the 2024 dataset contains 3,305 variables on 6,484 universities in the US!

I have filtered that 2024 dataset to only include schools which confer majority baccalaureate degrees and where the majority of those degrees are in the arts and sciences based on the Carnegie Classification system. In other words, I filtered the data down to the schools which are "similar" to Bucknell (including Bucknell itself) and picked out some variables for us to explore.

## Data Dictionary

Below are the code names and descriptions of the variables in our dataset.

-   `UNITID`: Unique identifier

-   `INSTNM`: Name of institution

-   `CITY`: City

-   `STABBR`: State

-   `HIGHDEG`: Highest degree awarded (0 = Non-degree grants, 1 = Certificate degree, 2 = Associate degree, 3 = Bachelor's degree, 4 = Graduate degree)

-   `PREDDEG`: Predominant undergraduate degree awarded (0 = Not classified, 1 = Predominantly certificate-degree granting, 2 = Predominantly associate's-degree granting, 3 = Predominantly bachelor's-degree granting, 4 = Entirely graduate-degree granting)

-   `CONTROL`: Ownership (1 = Public, 2 = Private non-profit, 3 = Private for-profit)

-   `HBCU`: Flag for Historically Black College and University

-   `TUITFTE`: Net tuition revenue per full-time equivalent student

-   `AVGFACSAL`: Average faculty salary

-   `ADM_RATE`: Admission rate

-   `SATVR75`: 75th percentile of SAT scores at the institution (critical reading)

-   `SATMT75`: 75th percentile of SAT scores at the institution (math)

-   `ACTCM75`: 75th percentile of the ACT cumulative score

-   `COSTT4_A`: The average annual total cost of attendance, including tuition and fees, books and supplies, and living expenses for all full-time, first-time, degree/certificate-seeking undergraduates who receive Title IV aid.

-   `NPT4_PRIV`: The average annual total cost of attendance, including tuition and fees, books and supplies, and living expenses, minus the average grant/scholarship aid

-   `UGDS`: Enrollment of undergraduate certificate/degree-seeking students

-   `UG25ABV`: Percentage of undergraduates aged 25 and above

-   `PCTFLOAN_DCS`: Percentage of degree/certificate-seeking undergraduate students awarded a federal loan

-   `PCTPELL_DCS`: Percentage of degree/certificate-seeking undergraduate students awarded a Pell Grant

-   `DEBT_MDN`: The median original amount of the loan principal upon entering repayment

-   `C100_4`: Completion rate for first-time, full-time students at four-year institutions (100% of expected time to completion)

-   `RET_FT4`: First-time, full-time student retention rate at four-year institutions

-   `MD_EARN_WNE_5YR`: Median earnings of graduates working and not enrolled 5 years after completing

# Load the Data

Run the following code to load the data.

```{r}
# Load the data
colleges <- read_csv("data/ccbasic21.csv") 

```


# Recap: Data wrangling from last session

![](img/dplyr_wrangling.png)

Data wrangling = any transformations done on the data.

## Some Thoughts on Wrangling

-   Data are messy. Be prepared to wrangle.

> "Tidy datasets are all alike, but every messy dataset is messy in its own way." -- Hadley Wickham

-   Before you start writing code ask yourself, what do I expect the wrangled data to look like? How many rows do I expect? How many columns?
-   Don't try to wrangle all at once.
    -   Write one line of code. Run it. And then keep going.
-   Give the wrangled dataset a new name if you are removing rows or changing the structure drastically.


# Main Data Wrangling Operations in `dplyr`

## `summarize()`: Summarize variable(s)

What is the average admission rate? What is the lowest admission rate?

```{r}
colleges_summary <- summarize(colleges, 
                              mean_admit = mean(ADM_RATE, na.rm = TRUE),
                              lowest_admit = min(ADM_RATE, na.rm = TRUE) )
colleges_summary
```

## `count()`: Add up number of rows for each category

How many historically black colleges and universities are in the dataset? Of those, how many award graduate degrees?

```{r}
count(colleges, HBCU)
count(colleges, HBCU, HIGHDEG)
```

## `mutate()`: Modify an existing variable or add new variables

Three examples below:

* Adding a new variable called `Location`: indicates if a school is in PA or not.
* Creating `HIGHDEG_CAT`: Which takes the numerical varaible `HIGHDEG` and creates a categorical version.
* Fixing `DEBT_MDN` so that `R` stores it as a numerical variable, not a categorical variable (which `R` calls a character vector).

```{r}
colleges <- mutate(colleges, 
                   Location = if_else(STABBR == "PA", "PA", "NOT PA"),
                   HIGHDEG_CAT = case_match(HIGHDEG,
                                            3 ~ "Bachelor's degree",
                                            4 ~ "Graduate degree"),
                   DEBT_MDN = as.numeric(DEBT_MDN))
#Check work
glimpse(colleges)
count(colleges, Location)
count(colleges, HIGHDEG_CAT)
```

## `select()`: Extract variables

Let's create a new dataset that only has the school name and location.

```{r}
colleges2 <- select(colleges, INSTNM, Location)
```

## `filter()`: Extract cases

Let's filter down to schools that are:

-   In the mid-atlantic: PA, NJ, VA, MD, DE, WV, DC
-   Have undergraduate enrollments over 1000 students
-   Don't have grad students

```{r}
colleges3 <- filter(colleges, 
                    STABBR %in% c("PA", "NJ", "VA", "MD", "DE", "WV", "DC"),
       UGDS > 1000, 
       HIGHDEG != 4)
```

Let's filter down to just Bucknell.

```{r}
bucknell <- filter(colleges, INSTNM == "Bucknell University")
```

## `drop_na()`: Remove rows that have missing values for certain variables

Let's remove rows that are missing an admissions rate.

```{r}
colleges_adm_rate_complete <- drop_na(colleges, ADM_RATE)
```

# More wrangling functions


## `arrange()`: Sort the cases

Let's sort rows by their admissions rate. Which schools has the lowest admissions rate? Which has the highest?

```{r}
arrange(colleges, ADM_RATE)
arrange(colleges, desc(ADM_RATE))
```

## The pipe: `%>%` or `|>` for chaining together multiple wranglings

If you want to do multiple operations at once, you should use [the pipe](https://magrittr.tidyverse.org/reference/pipe.html).

Suppose we want to look at `INSTNM`, `Location`, `ADM_RATE`, `UGDS`, `RET_FT4`, and `MD_EARN_WNE_5YR` for schools in PA that reported an admissions rate and we want to arrange the schools from largest undergraduate class to smallest undergraduate class.

```{r}
PA_colleges <- colleges %>%
  mutate(Location = if_else(STABBR == "PA", "PA", "Not PA")) %>%
  select(INSTNM, Location, ADM_RATE, UGDS, RET_FT4, MD_EARN_WNE_5YR) %>%
  filter(Location == "PA") %>%
  drop_na(ADM_RATE) %>%
  arrange(desc(UGDS))
PA_colleges
```

## `group_by()`: Perform actions by certain groups

For each of the Mid-Atlantic states, what is the average admission rate and how many schools are in each state?

```{r}
filter(colleges, STABBR %in% c("PA", "NJ", "VA", "MD", "DE", "WV", "DC")) %>%
  drop_na(ADM_RATE) %>%
  group_by(STABBR) %>%
  summarize(mean_admit = mean(ADM_RATE), count = n())
```

## How can I combine two datasets?

* Often the data is stored across several datasets and you want to combine them into one in a principled way.
* Need a key that links the two datasets.

```{r}
# Load data from the Opportunity Insights lab
opportunity_insights <- read_csv("data/opportunity_insights.csv")
```

Suppose we want to add the upward mobility information from the Opportunity Insights dataset to our colleges dataset.  [Opportunity Insight](https://opportunityinsights.org/) is a research initiative based at Harvard University and led by Raj Chetty, John Friedman, and Nathaniel Hendren, with the goal of improving upward mobility in the United States by studying barriers to economic opportunity and translating findings into policy change.  They defined a college's mobility rate as the percentage of students with parents in the bottom income quintile who ended up in the top $x$\% (in their mid-30s). The variables `mr_kq5_pq1` and `mr_ktop1_pq1` and refer to the percentage of students with parents in the bottom income quintile who ended up in the top 20\% and top 1\%, respectively.

Let's first look at smaller datasets so we can explore the different types of data joins.  What are the key variables?

```{r}
# Create smaller versions
colleges_nyc <- colleges %>%
  select(INSTNM, CITY, STABBR, ADM_RATE) %>%
  filter(CITY == "New York")
colleges_nyc

opp_ny <- opportunity_insights %>%
  filter(state == "NY", tier_name == "Selective private")
opp_ny
```

Three common types of joins:

```{r}
# The inner join
smallest <- inner_join(colleges_nyc, opp_ny, join_by("INSTNM" == "name"))
smallest

# The full join
largest <- full_join(colleges_nyc, opp_ny, join_by("INSTNM" == "name"))
largest

# The left join
middle <- left_join(colleges_nyc, opp_ny, join_by("INSTNM" == "name"))
middle
```

Which join should we use if we want to add the upward mobility information to our colleges dataset?

```{r}
colleges_plus <- left_join(colleges, opportunity_insights, join_by("INSTNM" == "name"))
```


## Your Optional Homework

If using your own data, do some wrangling that help answer questions of interest to you.


For the provided data, try to complete the following tasks.

a. How many schools are in each of the categories of `PREDDEG`?

```{r}
count(colleges, PREDDEG)
```



b. Create a dataset that only contains schools that are predominantly bachelor's degree granting.  Use this dataset for the following questions c and d.

```{r}
colleges_b <- filter(colleges, PREDDEG == 3)
```


c. Compute the minimum, maximum, and median values of the median earnings of graduates working and not enrolled 5 years after completing.   Useful `R` functions here are: `min()`, `max()`, `median()`.

```{r}
colleges_b %>%
  drop_na(MD_EARN_WNE_5YR) %>%
  summarize(min_earn = min(MD_EARN_WNE_5YR), max_earn = max(MD_EARN_WNE_5YR),
            med_earn = median(MD_EARN_WNE_5YR))
```


d. Repeat part (c) but this time compute the summary statistics for both HBCUs and non-HBCUs.  

```{r}
colleges_b %>%
  group_by(HBCU) %>%
  drop_na(MD_EARN_WNE_5YR) %>%
  summarize(min_earn = min(MD_EARN_WNE_5YR), max_earn = max(MD_EARN_WNE_5YR),
            med_earn = median(MD_EARN_WNE_5YR))
```

e. Create a dataset of just the HBCUs and add the Opportunity Insights variables to that dataset.   How many of the HBCUs in our dataset are in the Opportunity Insights dataset?

```{r}
hbcus <- colleges %>%
  filter(HBCU == 1) %>%
  left_join(opportunity_insights, join_by("INSTNM" == "name"))

# If we only want to keep the hbcus that are also in the Opp Insights dataset, change the join
hbcus <- colleges %>%
  filter(HBCU == 1) %>%
  inner_join(opportunity_insights, join_by("INSTNM" == "name"))
```


f. Ask some of your own questions of the data and then wrangle the data in order to answer them.


# Resources for Learning More about Data Wrangling with `dplyr`

-   Modern Dive's chapter on [Data Wrangling](https://moderndive.com/v2/wrangling.html)
-   R for Data Science's chapter on [Data Transformation](https://r4ds.hadley.nz/data-transform.html)
-   `dplyr` cheatsheet: <https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-transformation.pdf>

